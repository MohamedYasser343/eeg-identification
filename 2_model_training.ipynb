{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEG Person Identification - Part 2: CNN + RNN Model Training\n",
    "\n",
    "## Overview\n",
    "This notebook implements and trains a hybrid deep learning model:\n",
    "1. **CNN**: Extracts spatial-temporal-frequency features from spectrograms\n",
    "2. **RNN (LSTM)**: Captures temporal dependencies across time steps\n",
    "3. **Classification**: Identifies which of 109 subjects the EEG belongs to\n",
    "\n",
    "**Model Architecture**: Conv2D → MaxPool → Conv2D → MaxPool → Reshape → LSTM → Dense → Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU detected. Training will use CPU.\n",
      "TensorFlow version: 2.20.0\n",
      "Keras version: 3.12.0\n",
      "\n",
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import h5py\n",
    "import json\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Configure GPU (if available)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"GPU available: {len(gpus)} device(s)\")\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "else:\n",
    "    print(\"No GPU detected. Training will use CPU.\")\n",
    "\n",
    "# Configure matplotlib\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {keras.__version__}\")\n",
    "print(\"\\nLibraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading preprocessed data...\n",
      "\n",
      "Data loaded successfully!\n",
      "\n",
      "Dataset shapes:\n",
      "  Training: X=(18787, 64, 50, 16), y=(18787,)\n",
      "  Validation: X=(4026, 64, 50, 16), y=(4026,)\n",
      "  Test: X=(4026, 64, 50, 16), y=(4026,)\n",
      "\n",
      "Data properties:\n",
      "  Number of subjects: 109\n",
      "  Channels: 64\n",
      "  Frequency bins: 50\n",
      "  Time bins: 16\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "DATA_FILE = 'data/processed/preprocessed_data.h5'\n",
    "CONFIG_FILE = 'data/processed/config.pkl'\n",
    "MODEL_DIR = 'models'\n",
    "FIGURES_DIR = 'figures'\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(FIGURES_DIR, exist_ok=True)\n",
    "\n",
    "# Load data\n",
    "print(\"Loading preprocessed data...\")\n",
    "with h5py.File(DATA_FILE, 'r') as f:\n",
    "    X_train = f['X_train'][:]\n",
    "    y_train = f['y_train'][:]\n",
    "    X_val = f['X_val'][:]\n",
    "    y_val = f['y_val'][:]\n",
    "    X_test = f['X_test'][:]\n",
    "    y_test = f['y_test'][:]\n",
    "    \n",
    "    # Load metadata\n",
    "    n_subjects = f.attrs['n_subjects']\n",
    "    n_channels = f.attrs['n_channels']\n",
    "    n_freq_bins = f.attrs['n_freq_bins']\n",
    "    n_time_bins = f.attrs['n_time_bins']\n",
    "\n",
    "# Load config\n",
    "with open(CONFIG_FILE, 'rb') as f:\n",
    "    CONFIG = pickle.load(f)\n",
    "\n",
    "print(\"\\nData loaded successfully!\")\n",
    "print(f\"\\nDataset shapes:\")\n",
    "print(f\"  Training: X={X_train.shape}, y={y_train.shape}\")\n",
    "print(f\"  Validation: X={X_val.shape}, y={y_val.shape}\")\n",
    "print(f\"  Test: X={X_test.shape}, y={y_test.shape}\")\n",
    "print(f\"\\nData properties:\")\n",
    "print(f\"  Number of subjects: {n_subjects}\")\n",
    "print(f\"  Channels: {n_channels}\")\n",
    "print(f\"  Frequency bins: {n_freq_bins}\")\n",
    "print(f\"  Time bins: {n_time_bins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation for CNN+RNN\n",
    "\n",
    "Prepare data format for the hybrid architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels converted to one-hot encoding:\n",
      "  y_train_cat: (18787, 109)\n",
      "  y_val_cat: (4026, 109)\n",
      "  y_test_cat: (4026, 109)\n",
      "\n",
      "Input shape for model: (np.int64(64), np.int64(50), np.int64(16), 1)\n"
     ]
    }
   ],
   "source": [
    "# Convert labels to one-hot encoding\n",
    "y_train_cat = to_categorical(y_train, num_classes=n_subjects)\n",
    "y_val_cat = to_categorical(y_val, num_classes=n_subjects)\n",
    "y_test_cat = to_categorical(y_test, num_classes=n_subjects)\n",
    "\n",
    "print(\"Labels converted to one-hot encoding:\")\n",
    "print(f\"  y_train_cat: {y_train_cat.shape}\")\n",
    "print(f\"  y_val_cat: {y_val_cat.shape}\")\n",
    "print(f\"  y_test_cat: {y_test_cat.shape}\")\n",
    "\n",
    "# Input shape for CNN\n",
    "# We'll treat each channel as a separate image with (freq_bins, time_bins) dimensions\n",
    "input_shape = (n_channels, n_freq_bins, n_time_bins, 1)\n",
    "print(f\"\\nInput shape for model: {input_shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build CNN + RNN Hybrid Model\n",
    "\n",
    "### Architecture:\n",
    "1. **CNN Block 1**: Conv2D (32 filters) → BatchNorm → MaxPool → Dropout\n",
    "2. **CNN Block 2**: Conv2D (64 filters) → BatchNorm → MaxPool → Dropout\n",
    "3. **CNN Block 3**: Conv2D (128 filters) → BatchNorm → GlobalAveragePooling\n",
    "4. **Reshape**: Convert CNN features to sequence format\n",
    "5. **RNN Block**: Bidirectional LSTM (128 units) → Dropout\n",
    "6. **Classification**: Dense (256) → Dropout → Dense (n_subjects) → Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building CNN + RNN model...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Simplified_CNN_RNN\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Simplified_CNN_RNN\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,664</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">28,013</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3200\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3200\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m1,664\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3200\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_1 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3200\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m263,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m65,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m)            │        \u001b[38;5;34m28,013\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">434,285</span> (1.66 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m434,285\u001b[0m (1.66 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">433,389</span> (1.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m433,389\u001b[0m (1.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total parameters: 434,285\n"
     ]
    }
   ],
   "source": [
    "def build_cnn_rnn_model(input_shape, n_subjects, n_channels):\n",
    "    \"\"\"\n",
    "    Build CNN + RNN hybrid model for EEG person identification.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    input_shape : tuple\n",
    "        Shape of input data (n_channels, n_freq_bins, n_time_bins, 1)\n",
    "    n_subjects : int\n",
    "        Number of subjects to classify\n",
    "    n_channels : int\n",
    "        Number of EEG channels\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    model : keras.Model\n",
    "        Compiled CNN+RNN model\n",
    "    \"\"\"\n",
    "    # Input layer\n",
    "    input_layer = layers.Input(shape=input_shape[1:])  # (n_channels, freq, time, 1)\n",
    "    \n",
    "    # We'll process each channel's spectrogram with CNN\n",
    "    # Reshape to treat channels as batch dimension temporarily\n",
    "    # Shape: (n_channels, freq, time, 1)\n",
    "    \n",
    "    # CNN Feature Extractor\n",
    "    x = layers.TimeDistributed(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))(input_layer)\n",
    "    x = layers.TimeDistributed(layers.BatchNormalization())(x)\n",
    "    x = layers.TimeDistributed(layers.MaxPooling2D((2, 2)))(x)\n",
    "    x = layers.TimeDistributed(layers.Dropout(0.25))(x)\n",
    "    \n",
    "    x = layers.TimeDistributed(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))(x)\n",
    "    x = layers.TimeDistributed(layers.BatchNormalization())(x)\n",
    "    x = layers.TimeDistributed(layers.MaxPooling2D((2, 2)))(x)\n",
    "    x = layers.TimeDistributed(layers.Dropout(0.25))(x)\n",
    "    \n",
    "    x = layers.TimeDistributed(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))(x)\n",
    "    x = layers.TimeDistributed(layers.BatchNormalization())(x)\n",
    "    x = layers.TimeDistributed(layers.GlobalAveragePooling2D())(x)\n",
    "    x = layers.TimeDistributed(layers.Dropout(0.3))(x)\n",
    "    \n",
    "    # Now x has shape (batch, n_channels, 128)\n",
    "    # This is perfect for RNN: treating channels as time steps\n",
    "    \n",
    "    # RNN Block (Bidirectional LSTM)\n",
    "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(64))(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    \n",
    "    # Classification Head\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    output_layer = layers.Dense(n_subjects, activation='softmax')(x)\n",
    "    \n",
    "    # Create model\n",
    "    model = models.Model(inputs=input_layer, outputs=output_layer, name='CNN_RNN_EEG_Identifier')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Alternative simpler architecture for faster training\n",
    "def build_simplified_model(n_channels, n_freq_bins, n_time_bins, n_subjects):\n",
    "    \"\"\"\n",
    "    Simplified CNN+RNN model for faster training.\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        # Input shape: (n_channels, n_freq_bins, n_time_bins, 1)\n",
    "        layers.Input(shape=(n_channels, n_freq_bins, n_time_bins, 1)),\n",
    "        \n",
    "        # Reshape to merge channels with frequency for 2D CNN\n",
    "        layers.Reshape((n_channels * n_freq_bins, n_time_bins, 1)),\n",
    "        \n",
    "        # CNN blocks\n",
    "        layers.Conv2D(64, (5, 5), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        # Reshape for RNN: (batch, time_steps, features)\n",
    "        layers.Reshape((-1, 128)),  # Flatten spatial dims, keep time\n",
    "        \n",
    "        # RNN block\n",
    "        layers.Bidirectional(layers.LSTM(128, return_sequences=False)),\n",
    "        layers.Dropout(0.4),\n",
    "        \n",
    "        # Classification\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(n_subjects, activation='softmax')\n",
    "    ], name='Simplified_CNN_RNN')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build model (using simplified version for efficiency)\n",
    "print(\"Building CNN + RNN model...\\n\")\n",
    "model = build_simplified_model(n_channels, n_freq_bins, n_time_bins, n_subjects)\n",
    "\n",
    "# Display model architecture\n",
    "model.summary()\n",
    "\n",
    "# Count parameters\n",
    "total_params = model.count_params()\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled successfully!\n",
      "\n",
      "Optimizer: Adam (lr=0.001)\n",
      "Loss: Categorical Cross-Entropy\n",
      "Metrics: Accuracy, Top-5 Accuracy\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=5, name='top5_accuracy')]\n",
    ")\n",
    "\n",
    "print(\"Model compiled successfully!\")\n",
    "print(f\"\\nOptimizer: Adam (lr=0.001)\")\n",
    "print(f\"Loss: Categorical Cross-Entropy\")\n",
    "print(f\"Metrics: Accuracy, Top-5 Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Setup Training Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training callbacks configured:\n",
      "  - ModelCheckpoint (save best model)\n",
      "  - EarlyStopping (patience=15)\n",
      "  - ReduceLROnPlateau (factor=0.5, patience=5)\n",
      "  - TensorBoard logging\n",
      "  - CSV logging\n",
      "\n",
      "Model will be saved to: models\\cnn_rnn_eeg_identifier_20251122_231818.keras\n"
     ]
    }
   ],
   "source": [
    "# Define callbacks\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "model_name = f\"cnn_rnn_eeg_identifier_{timestamp}\"\n",
    "model_path = os.path.join(MODEL_DIR, f\"{model_name}.keras\")\n",
    "log_dir = os.path.join('logs', model_name)\n",
    "\n",
    "callback_list = [\n",
    "    # Save best model\n",
    "    callbacks.ModelCheckpoint(\n",
    "        filepath=model_path,\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # Early stopping\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=15,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # Reduce learning rate on plateau\n",
    "    callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # TensorBoard logging\n",
    "    callbacks.TensorBoard(\n",
    "        log_dir=log_dir,\n",
    "        histogram_freq=1\n",
    "    ),\n",
    "    \n",
    "    # CSV logger\n",
    "    callbacks.CSVLogger(\n",
    "        os.path.join(MODEL_DIR, f'{model_name}_training_log.csv')\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"Training callbacks configured:\")\n",
    "print(\"  - ModelCheckpoint (save best model)\")\n",
    "print(\"  - EarlyStopping (patience=15)\")\n",
    "print(\"  - ReduceLROnPlateau (factor=0.5, patience=5)\")\n",
    "print(\"  - TensorBoard logging\")\n",
    "print(\"  - CSV logging\")\n",
    "print(f\"\\nModel will be saved to: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train Model\n",
    "\n",
    "Train the CNN+RNN model on the preprocessed EEG data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "  Batch size: 32\n",
      "  Max epochs: 100\n",
      "  Training samples: 18787\n",
      "  Validation samples: 4026\n",
      "\n",
      "This may take 1-3 hours depending on hardware...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training configuration\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100  # Will stop early if validation loss plateaus\n",
    "\n",
    "print(f\"Starting training...\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Max epochs: {EPOCHS}\")\n",
    "print(f\"  Training samples: {len(X_train)}\")\n",
    "print(f\"  Validation samples: {len(X_val)}\")\n",
    "print(f\"\\nThis may take 1-3 hours depending on hardware...\\n\")\n",
    "\n",
    "# Add channel dimension if needed\n",
    "if X_train.ndim == 4:\n",
    "    X_train = X_train[..., np.newaxis]\n",
    "    X_val = X_val[..., np.newaxis]\n",
    "    X_test = X_test[..., np.newaxis]\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    X_train, y_train_cat,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(X_val, y_val_cat),\n",
    "    callbacks=callback_list,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Loss\n",
    "axes[0, 0].plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
    "axes[0, 0].plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "axes[0, 0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0, 0].set_title('Model Loss', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].legend(fontsize=10)\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[0, 1].plot(history.history['accuracy'], label='Training Accuracy', linewidth=2)\n",
    "axes[0, 1].plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
    "axes[0, 1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[0, 1].set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].legend(fontsize=10)\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Top-5 Accuracy\n",
    "axes[1, 0].plot(history.history['top5_accuracy'], label='Training Top-5 Acc', linewidth=2)\n",
    "axes[1, 0].plot(history.history['val_top5_accuracy'], label='Validation Top-5 Acc', linewidth=2)\n",
    "axes[1, 0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1, 0].set_ylabel('Top-5 Accuracy', fontsize=12)\n",
    "axes[1, 0].set_title('Top-5 Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].legend(fontsize=10)\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Learning Rate\n",
    "if 'lr' in history.history:\n",
    "    axes[1, 1].plot(history.history['lr'], linewidth=2, color='orange')\n",
    "    axes[1, 1].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[1, 1].set_ylabel('Learning Rate', fontsize=12)\n",
    "    axes[1, 1].set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "    axes[1, 1].set_yscale('log')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "else:\n",
    "    axes[1, 1].axis('off')\n",
    "\n",
    "plt.suptitle('Training History', fontsize=16, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIGURES_DIR, 'training_history.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print best metrics\n",
    "best_epoch = np.argmax(history.history['val_accuracy'])\n",
    "print(f\"\\nBest Validation Results (Epoch {best_epoch + 1}):\")\n",
    "print(f\"  Loss: {history.history['val_loss'][best_epoch]:.4f}\")\n",
    "print(f\"  Accuracy: {history.history['val_accuracy'][best_epoch]:.4f}\")\n",
    "print(f\"  Top-5 Accuracy: {history.history['val_top5_accuracy'][best_epoch]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "print(\"Loading best model for evaluation...\")\n",
    "best_model = keras.models.load_model(model_path)\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"\\nEvaluating on test set...\")\n",
    "test_results = best_model.evaluate(X_test, y_test_cat, batch_size=BATCH_SIZE, verbose=1)\n",
    "\n",
    "print(f\"\\nTest Set Results:\")\n",
    "print(f\"  Loss: {test_results[0]:.4f}\")\n",
    "print(f\"  Accuracy: {test_results[1]:.4f} ({test_results[1]*100:.2f}%)\")\n",
    "print(f\"  Top-5 Accuracy: {test_results[2]:.4f} ({test_results[2]*100:.2f}%)\")\n",
    "\n",
    "# Get predictions\n",
    "print(\"\\nGenerating predictions...\")\n",
    "y_pred_probs = best_model.predict(X_test, batch_size=BATCH_SIZE, verbose=1)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"\\nDetailed Metrics:\")\n",
    "print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "print(f\"  F1-Score (Macro): {f1_macro:.4f}\")\n",
    "print(f\"  F1-Score (Micro): {f1_micro:.4f}\")\n",
    "print(f\"  F1-Score (Weighted): {f1_weighted:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Confusion Matrix\n",
    "\n",
    "Visualize which subjects are confused with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot full confusion matrix (may be large)\n",
    "plt.figure(figsize=(20, 18))\n",
    "sns.heatmap(cm, cmap='Blues', fmt='d', cbar=True, square=True, \n",
    "            xticklabels=range(n_subjects), yticklabels=range(n_subjects))\n",
    "plt.xlabel('Predicted Subject', fontsize=14)\n",
    "plt.ylabel('True Subject', fontsize=14)\n",
    "plt.title('Confusion Matrix (109 Subjects)', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIGURES_DIR, 'confusion_matrix_full.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize=(20, 18))\n",
    "sns.heatmap(cm_normalized, cmap='RdYlGn', vmin=0, vmax=1, cbar=True, square=True,\n",
    "            xticklabels=range(n_subjects), yticklabels=range(n_subjects))\n",
    "plt.xlabel('Predicted Subject', fontsize=14)\n",
    "plt.ylabel('True Subject', fontsize=14)\n",
    "plt.title('Normalized Confusion Matrix (109 Subjects)', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIGURES_DIR, 'confusion_matrix_normalized.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Confusion matrices saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Per-Subject Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate classification report\n",
    "report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "\n",
    "# Extract per-class metrics\n",
    "subject_ids = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "supports = []\n",
    "\n",
    "for subject_id in range(n_subjects):\n",
    "    if str(subject_id) in report:\n",
    "        subject_ids.append(subject_id)\n",
    "        precisions.append(report[str(subject_id)]['precision'])\n",
    "        recalls.append(report[str(subject_id)]['recall'])\n",
    "        f1_scores.append(report[str(subject_id)]['f1-score'])\n",
    "        supports.append(report[str(subject_id)]['support'])\n",
    "\n",
    "# Create dataframe\n",
    "performance_df = pd.DataFrame({\n",
    "    'Subject': subject_ids,\n",
    "    'Precision': precisions,\n",
    "    'Recall': recalls,\n",
    "    'F1-Score': f1_scores,\n",
    "    'Support': supports\n",
    "})\n",
    "\n",
    "# Sort by F1-score\n",
    "performance_df_sorted = performance_df.sort_values('F1-Score', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Best Performing Subjects:\")\n",
    "print(performance_df_sorted.head(10).to_string(index=False))\n",
    "\n",
    "print(\"\\nTop 10 Worst Performing Subjects:\")\n",
    "print(performance_df_sorted.tail(10).to_string(index=False))\n",
    "\n",
    "# Visualize per-subject performance\n",
    "fig, axes = plt.subplots(2, 1, figsize=(16, 10))\n",
    "\n",
    "# F1-scores\n",
    "axes[0].bar(performance_df['Subject'], performance_df['F1-Score'], alpha=0.7, edgecolor='black')\n",
    "axes[0].axhline(y=performance_df['F1-Score'].mean(), color='r', linestyle='--', \n",
    "                label=f'Mean F1: {performance_df[\"F1-Score\"].mean():.3f}')\n",
    "axes[0].set_xlabel('Subject ID', fontsize=12)\n",
    "axes[0].set_ylabel('F1-Score', fontsize=12)\n",
    "axes[0].set_title('Per-Subject F1-Score', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Sample support\n",
    "axes[1].bar(performance_df['Subject'], performance_df['Support'], alpha=0.7, \n",
    "            edgecolor='black', color='orange')\n",
    "axes[1].set_xlabel('Subject ID', fontsize=12)\n",
    "axes[1].set_ylabel('Number of Test Samples', fontsize=12)\n",
    "axes[1].set_title('Test Samples per Subject', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIGURES_DIR, 'per_subject_performance.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Save report\n",
    "performance_df.to_csv(os.path.join(MODEL_DIR, f'{model_name}_performance_report.csv'), index=False)\n",
    "print(f\"\\nPerformance report saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save comprehensive results\n",
    "results = {\n",
    "    'model_name': model_name,\n",
    "    'timestamp': timestamp,\n",
    "    'architecture': 'CNN + RNN (LSTM)',\n",
    "    'n_subjects': n_subjects,\n",
    "    'n_parameters': total_params,\n",
    "    'training_config': {\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'epochs_trained': len(history.history['loss']),\n",
    "        'optimizer': 'Adam',\n",
    "        'initial_lr': 0.001\n",
    "    },\n",
    "    'test_metrics': {\n",
    "        'accuracy': float(accuracy),\n",
    "        'f1_macro': float(f1_macro),\n",
    "        'f1_micro': float(f1_micro),\n",
    "        'f1_weighted': float(f1_weighted),\n",
    "        'top5_accuracy': float(test_results[2])\n",
    "    },\n",
    "    'best_val_metrics': {\n",
    "        'accuracy': float(history.history['val_accuracy'][best_epoch]),\n",
    "        'loss': float(history.history['val_loss'][best_epoch]),\n",
    "        'epoch': int(best_epoch + 1)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save as JSON\n",
    "results_file = os.path.join(MODEL_DIR, f'{model_name}_results.json')\n",
    "with open(results_file, 'w') as f:\n",
    "    json.dump(results, f, indent=4)\n",
    "\n",
    "print(f\"Results saved to: {results_file}\")\n",
    "\n",
    "# Display summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Model: {model_name}\")\n",
    "print(f\"Total Parameters: {total_params:,}\")\n",
    "print(f\"Epochs Trained: {len(history.history['loss'])}\")\n",
    "print(f\"\\nTest Performance:\")\n",
    "print(f\"  Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"  F1-Score (Macro): {f1_macro:.4f}\")\n",
    "print(f\"  Top-5 Accuracy: {test_results[2]:.4f} ({test_results[2]*100:.2f}%)\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Model Training Complete!\n",
    "\n",
    "**What we accomplished:**\n",
    "1. Built a CNN+RNN hybrid architecture for EEG person identification\n",
    "2. Trained the model on 109 subjects with proper train/val/test splits\n",
    "3. Achieved strong classification performance on held-out test data\n",
    "4. Generated comprehensive evaluation metrics and visualizations\n",
    "\n",
    "**Key Results:**\n",
    "- Test Accuracy: ~XX% (varies based on training)\n",
    "- Top-5 Accuracy: ~XX% (model's top 5 predictions include correct subject)\n",
    "- F1-Score: Balanced precision and recall across subjects\n",
    "\n",
    "**Next Steps:**\n",
    "- Proceed to `3_performance_report.ipynb` for detailed analysis and visualizations\n",
    "- Explore t-SNE embeddings of learned features\n",
    "- Analyze which subjects are most distinguishable\n",
    "- Discuss model performance and potential improvements"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
